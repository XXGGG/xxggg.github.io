---
title: ğŸ•·ï¸ã€çˆ¬è™«ç¬¬é›¶æ­¥ã€ğŸ•·ï¸
---

## éœ€è¦äº†è§£çš„çŸ¥è¯†ç‚¹
é¦–å…ˆçˆ¬è™«çš„ç¬¬ä¸€æ­¥å°±æ˜¯éœ€è¦äº†è§£åˆ°ï¼Œçˆ¬è™«éœ€è¦çŸ¥é“çš„å“ªäº›çŸ¥è¯†ç‚¹ï¼
1. ç›®å‰çˆ¬è™«ä½¿ç”¨çš„æ˜¯ã€Pythonã€‘
2. éœ€è¦ä½¿ç”¨åˆ°å¾ˆå¤šã€Pythonã€‘ç¬¬ä¸‰æ–¹åº“ã€urllibã€‘ã€BeautifulSoupã€‘...
3. éœ€è¦ä¼šæ•°æ®åº“è¯­å¥ã€SQliteã€‘æˆ–ã€MySqlã€‘


## Pythonçˆ¬è™«åŸºæœ¬æµç¨‹
### 1. å‡†å¤‡å·¥ä½œ
é€šè¿‡æµè§ˆå™¨æŸ¥çœ‹åˆ†æç›®æ ‡ç½‘é¡µï¼Œå­¦ä¹ ç¼–ç¨‹åŸºç¡€è§„èŒƒ
### 2. è·å–æ•°æ®
é€šè¿‡HTTPåº“å‘ç›®æ ‡ç«™ç‚¹å‘èµ·è¯·æ±‚ï¼Œè¯·æ±‚å¯ä»¥åŒ…å«é¢å¤–çš„headerç­‰ä¿¡æ¯  
å¦‚æœæœåŠ¡å™¨èƒ½æ­£å¸¸å“åº”ï¼Œä¼šå¾—åˆ°ä¸€ä¸ªResponseï¼Œä¾¿æ˜¯æ‰€è¦è·å¾—çš„é¡µé¢å†…å®¹ã€‚
### 3. è§£æå†…å®¹
å¾—åˆ°çš„å†…å®¹å¯èƒ½æ˜¯HTMLã€jsonç­‰ï¼Œå¯ä»¥ç”¨**é¡µé¢è§£æåº“**ã€**æ­£åˆ™è¡¨è¾¾å¼**ç­‰è¿›è¡Œè§£æ
### 4. ä¿å­˜æ•°æ®
ä¿å­˜å½¢å¼å¤šæ ·ï¼Œå¯ä»¥å­˜ä¸ºæ–‡æœ¬ï¼Œä¹Ÿå¯ä»¥ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæˆ–è€…ä¿å­˜ç‰¹å®šæ ¼å¼çš„æ–‡ä»¶ã€‚

--- 
## ç¼–ç è§„èŒƒ
### 1.ä¸€èˆ¬Pythonç¨‹åºç¬¬ä¸€è¡Œéœ€è¦åŠ å…¥
```py
# -*- coding:uft-8 -*- 
æˆ–è€…
# coding=utf-8
```

### 2. Pythonæ–‡ä»¶ä¸­å¯ä»¥åŠ å…¥mainå‡½æ•°ç”¨äºæµ‹è¯•ç¨‹åº

```py
#å¯ä»¥æŠŠä»–å½“ä½œæ˜¯æ•´ä¸ªç¨‹åºçš„å¼€å§‹ï¼
if __name__ == "__main__":
```
---

## å¸¸ç”¨ç¬¬ä¸‰æ–¹åº“ğŸ‘‡
- urllib ï¼ˆ1.åˆ¶å®šURLã€è·å–â€œæ•´ä½“â€ç½‘é¡µæ•°æ®ï¼‰ã€Python3è‡ªå¸¦ã€‘
- bs4ã€BeautifulSoup ï¼ˆ2.ç½‘é¡µè§£æã€å˜æˆâ€œå¯ç­›é€‰â€æ•°æ®ï¼‰
- re ï¼ˆ3.æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿›è¡Œç­›é€‰ï¼Œæ•´ç†å‡ºæƒ³è¦çš„å†…å®¹ï¼‰ã€Python3è‡ªå¸¦ã€‘
- xlwt ï¼ˆ4.è¿›è¡Œexcelæ“ä½œï¼Œä¿å­˜è¿›excelæ–‡æ¡£é‡Œï¼‰
- sqlite3 ï¼ˆ4.è¿›è¡ŒSQLæ•°æ®åº“æ“ä½œï¼‰ã€Python3è‡ªå¸¦ã€‘

å®‰è£…æ–¹æ³•ï¼šğŸ‘‡
```sh
# python3è‡ªå¸¦çš„ä¸ç”¨å®‰è£…
pip install bs4
pip install xlwt
```
å¼•å…¥ï¼šğŸ‘‡  
```py
import urllib.request,urllib.error
from bs4 import BeautifulSoup
import re
import xwlt
import sqlite3
```

## ã€urllibã€‘çš„ä½¿ç”¨
- urllib.request.Request() æ¥è®¾ç½®è¯·æ±‚å¤´
- urllib.request.urlopen() æ¥è¯·æ±‚ç½‘é¡µæ•°æ®
```py
# å¼€å§‹çˆ¬å–æ•°æ®
def askURL(baseurl):
    #åœ¨çˆ¬è™«çš„æ—¶å€™ è¿™ä¸ªæ˜¯ä¸ªç®€å•çš„è®¾ç½®è¯·æ±‚å¤´çš„æ–¹æ³•
    head = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.54"
        }
    request = urllib.request.Request(baseurl,headers=head)
    #å› ä¸ºå¦‚æœä½ ä¸è®¾ç½®ï¼Œä»–ä»¬æœåŠ¡å™¨æ˜¯ä¼šçŸ¥é“ä½ æ˜¯pythonçˆ¬è™«æ¥æ‹¿æ•°æ®çš„ã€‚æ‰€ä»¥è¦ä¼ªè£…ä¸€ä¸‹
    html = ''
    #çˆ¬è™«ä¸€å®šè¦ä½¿ç”¨è¿™ä¸ªtry å› ä¸ºæ€•ç¨‹åºå‡ºé”™ çˆ¬ä¸å‡ºæ¥
    try:
        #ç„¶ååˆ©ç”¨ã€urllibé‡Œçš„requestçš„urlopenæ–¹æ³•ã€‘æ ¹æ®ä¸Šé¢çš„è¯·æ±‚å¤´å’Œurlçˆ¬å‡ºæ¥
        response = urllib.request.urlopen(request)
        #æŠŠçˆ¬åˆ°çš„å†…å®¹ã€å¯¹è±¡ã€‘èµ‹å€¼ç»™responseå˜é‡åè¯»å‡ºæ¥-ç”¨utf-8çš„æ ¼å¼è¯»å‡ºæ¥
        html = response.read().decode('utf-8')
    
    #å‡ºé”™äº†å°±ç”¨è¿™ä¸ªæŠ¥é”™
    except urllib.error.URLError as e:
        if hasattr(e,"code"):
            print(e.code)
        if hasattr(e,"reason"):
            print(e.reason)

    #æœ€åæŠŠçˆ¬åˆ°çš„æ•°æ®è¿”å›å‡ºå»
    return html
```

## æ¥è‡ªã€bs4ã€‘é‡Œçš„ã€BeautifuSoupã€‘

1. `from bs4 import BeautifulSoup` ã€å¼•å…¥ã€‘
2. `bs = BeautifulSoup(ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯çˆ¬å–å›æ¥çš„ç½‘é¡µçš„å˜é‡åï¼Œ"html.parser")` ã€è§£æã€‘
3. `bs.find_all("a")` ã€ç­›é€‰ã€‘ æŸ¥æ‰¾æ‰€æœ‰aæ ‡ç­¾ 

```py
# bsè§£æ reç­›é€‰ æ•´ç†æ•°æ®
def getData(baseurl):
    datalist = []
    html = askURL(baseurl) #åœ¨è¿™é‡Œè°ƒç”¨çˆ¬å– å¹¶å–å›æ•°æ®
    soup = BeautifulSoup(html,"html.parser") #è§£ææ•°æ®
    #æ¥åˆ°è¿™å°±ä»£è¡¨ å·²ç»çˆ¬å–åˆ°äº†ä¿¡æ¯
    
    #ä¸‹é¢è¿™æ˜¯æŠŠçˆ¬å–åˆ°çš„å†…å®¹è¿›è¡Œç­›é€‰ ï¼ˆåˆ©ç”¨reæ­£åˆ™ï¼‰
    for item in soup.find_all('div',class_="placeholder one-img-plc"):
        #ç”¨find_allæ‰¾å‡ºä¸€ä¸ªå¸¦æœ‰ç‰¹å®šclassçš„divï¼Œä»–ä»¬ä¼šå½¢æˆä¸€ä¸ªã€æ•°ç»„ã€‘
        # å†æŠŠè¿™ä¸ªæ•°ç»„éå†å‡ºæ¥ æˆ- item
        data = []
        item = str(item) #æŠŠitemå˜æˆå­—ç¬¦ä¸² å¥½ç”¨reæ­£åˆ™æ¥æŸ¥æ‰¾

        #ä¸‹é¢çš„finkLinkæ˜¯ äº‹å…ˆåˆ¶å®šå¥½çš„æ­£åˆ™è§„åˆ™ è€Œåé¢çš„itemå°±æ˜¯æ¯æ¡æ•°æ®çš„å­—ç¬¦ä¸²äº†
        link = re.findall(findLink,item)[0]
        #åŒæ ·çš„ä»–ä¼šè¿”å›ä¸€ä¸ªæ•°æ® äºæ˜¯ä¸ºäº†æ–¹ä¾¿å°±ä½¿ç”¨[0] æ¥ç›´æ¥å¾—åˆ°æ•°ç»„ç¬¬ä¸€ä¸ªæ•°æ®
        imgSrc = re.findall(findImgSrc,item)[0]
        title = re.findall(findTitle,item)[0]
        #ç»è¿‡ç½‘é¡µè§‚å¯Ÿ æ²¡æ—¶é—´çš„å°±æ˜¯å¹¿å‘Š
        time = re.findall(findTime,item)[0]

        if bool(time):
            data.append(link)
            data.append(imgSrc)
            data.append(title)
            data.append(time)
            #æŠŠæ•°æ®æ•´ç†å¥½ æ·»åŠ åˆ°data è¿™ä¸ªå˜é‡æ¥
            #æœ€åå†æŠŠdataè¿™ä¸€æ¡æ•°æ® æ•´ä½“çš„å¢åŠ è¿›datalist
            datalist.append(data)
        else: 
            print("è¿™ä¸ªæ˜¯å¹¿å‘Š")

    # æœ€åæŠŠè¿™ä¸ªdatalistå†è¿”å›å‡ºå» 
    return datalist
```
---

**é‚£ä¹ˆæˆ‘ä»¬è¿›è¡Œäº†urllibçš„çˆ¬å–ï¼ä¹Ÿè¿›è¡Œäº†BeautifulSoupçš„è§£æ è·Ÿreçš„ç­›é€‰ï¼Œæœ€åæ•´ç†å¥½äº†æ•°æ®æ•°ç»„åˆ—è¡¨datalist è¿”å›å‡ºå»è¿”å›åˆ°äº†å“ªé‡Œå‘¢ï¼Ÿ**

```py
if __name__ == "__main__":
    main()
    print('çˆ¬å–å®Œæˆï¼')

def main():
    baseurl = "https://m.ithome.com/"
    datalist = getData(baseurl)
    #ğŸ‘‡ä¸‹é¢æ˜¯ä¸ºäº†ä¿å­˜çˆ¬å–åˆ°çš„å†…å®¹
    savepath = ('.\\ITä¹‹å®¶æœ€æ–°æ–°é—».xls')
    saveData(datalist,savepath)
```
åœ¨è¿™é‡Œ main ä¸»ç¨‹åºå…¥å£ è¿™é‡Œ  
1. å…ˆå®šä¹‰å¥½ åŸºç¡€çš„é“¾æ¥  
2. ç„¶åè°ƒç”¨ getData è¿™ä¸ªè‡ªå®šä¹‰çš„å‡½æ•°å–çˆ¬å– datalistå°±ä¼šè¿”å›åˆ°è¿™é‡Œæ¥
3. åé¢ä¸¤æ­¥æ˜¯ä¸ºäº†ä¿å­˜æˆ‘ä»¬çˆ¬å–åˆ°çš„å†…å®¹

---

### æ­£åˆ™è¡¨è¾¾å¼ æœç´¢ - bs.find_all

- ä½¿ç”¨`search()`æ–¹æ³•æ¥åŒ¹é…å†…å®¹
```py
bs.find_all(re.compile("a"))
#æ‰¾åˆ°æœ‰å¸¦açš„ä¸œè¥¿
```
```py
bs.find_all(id="head")
#æ‰¾åˆ°idä¸ºheadçš„å†…å®¹
```

## cssé€‰æ‹©å™¨ æŸ¥æ‰¾ select
```py
bs.select('title')
#æŸ¥æ‰¾åˆ°è¿™ä¸ªæ ‡ç­¾
```
```py
bs.select(".class")
#æŸ¥æ‰¾åˆ°è¿™ä¸ªç±» è¿”å›ä¸€ä¸ªåˆ—è¡¨
bs.select("#id")
#æŸ¥æ‰¾åˆ°è¿™ä¸ªid è¿”å›ä¸€ä¸ªåˆ—è¡¨
bs.select("a[class='nav']")
#æŸ¥æ‰¾åˆ°è¿™ä¸ªclassæ˜¯navçš„aæ ‡ç­¾ è¿”å›ä¸€ä¸ªåˆ—è¡¨
```

## re æ­£åˆ™è¡¨è¾¾å¼
```py
re.findall('æ­£åˆ™è¡¨è¾¾å¼','è¢«éªŒè¯çš„è¯­å¥ã€å­—ç¬¦ä¸²')
re.findall('/d','123abc')
```
```py
re.sub('è¦æ›¿æ¢çš„æ­£åˆ™è¡¨è¾¾å¼','æ›¿æ¢çš„','è¢«æ›¿æ¢çš„å­—ç¬¦ä¸²')
re.sub('abc','Abc','abcdefg')
#subæ›¿æ¢
```







## æŠ¥é”™
- 418 ä»£è¡¨è¢«å‘ç°æ˜¯çˆ¬è™«

---


## å…¶ä»–

### è½¬æ¢æˆäºŒè¿›åˆ¶
```
bytes()
```
### ç™¾åº¦æœç´¢æŒ‡æ•°
[index.baidu.com](index.baidu.com)