(window.webpackJsonp=window.webpackJsonp||[]).push([[93],{578:function(t,v,_){"use strict";_.r(v);var a=_(4),r=Object(a.a)({},(function(){var t=this,v=t.$createElement,_=t._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h1",{attrs:{id:"the-【多功能网站】"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#the-【多功能网站】"}},[t._v("#")]),t._v(" THE - 【多功能网站】")]),t._v(" "),_("p",[t._v("the 来源于 the shy的the")]),t._v(" "),_("p",[t._v("这个网站是要设计成【多功能网站】"),_("br"),t._v("\n分别有：")]),t._v(" "),_("ol",[_("li",[t._v("首页新闻，搞笑段子")]),t._v(" "),_("li",[t._v("韩漫")]),t._v(" "),_("li",[t._v("电影【下载】")]),t._v(" "),_("li",[t._v("小说")]),t._v(" "),_("li",[t._v("网络流行语查询【合并XG词典】")])]),t._v(" "),_("h2",{attrs:{id:"技术栈"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#技术栈"}},[t._v("#")]),t._v(" 技术栈")]),t._v(" "),_("ol",[_("li",[t._v("用Python爬虫 爬取内容到MySQL数据库")]),t._v(" "),_("li",[t._v("用node.js搭建后台服务器和api接口")]),t._v(" "),_("li",[t._v("前端使用vue.js和vuetify的ui库来搭建实现响应式网站")])]),t._v(" "),_("h2",{attrs:{id:"实现步骤👇"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#实现步骤👇"}},[t._v("#")]),t._v(" 实现步骤👇")]),t._v(" "),_("h3",{attrs:{id:"爬虫【爬取it之家-手机端】"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#爬虫【爬取it之家-手机端】"}},[t._v("#")]),t._v(" 爬虫【爬取IT之家-手机端】")]),t._v(" "),_("p",[t._v("先用Python配合爬虫需要的所有第三方库爬取【IT之家-手机端】的新闻\n分别需要")]),t._v(" "),_("ol",[_("li",[t._v("首页【最新】当中的【焦点图】（单独存入一个数据表） ✔简单！")]),t._v(" "),_("li",[t._v("新闻列表【封面图片连接】【新闻原链接】【标题】")]),t._v(" "),_("li",[t._v("通过【原链接】再爬取【新闻具体时间】【新闻内容】（存入数据表）")])]),t._v(" "),_("h4",{attrs:{id:"遇到的难题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#遇到的难题"}},[t._v("#")]),t._v(" 遇到的难题")]),t._v(" "),_("ol",[_("li",[t._v("新闻需要定时爬取（程序需要定时执行）")])]),t._v(" "),_("p",[t._v("解决方法1："),_("a",{attrs:{href:"https://www.bilibili.com/video/BV1vt4y1C7kE?from=search&seid=8067132167847565362",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.bilibili.com/video/BV1vt4y1C7kE?from=search&seid=8067132167847565362"),_("OutboundLink")],1),t._v(" 根据这个b站视频里，用windows里面的【任务计划程序】 （每一小时运行一下爬虫.py程序）")]),t._v(" "),_("ol",{attrs:{start:"2"}},[_("li",[t._v("爬取的内容需要进行去重（合并重复的数据）")])]),t._v(" "),_("p",[t._v("解决方法1：在爬虫程序最后【存入数据库】的步骤中，先根据 原链接-【link】字段查询有没有之前就存在的，如果有就跳过存储，否则就把数据【存入数据库】")]),t._v(" "),_("ol",{attrs:{start:"3"}},[_("li",[t._v("爬虫的网页内容需要往下滑才能得到更多的内容，才能爬取到更多的内容。")])]),t._v(" "),_("p",[t._v("解决方法1：【暂时没有实施解决方法】【或许可以尝试 selenium】")]),t._v(" "),_("h2",{attrs:{id:"总问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总问题"}},[t._v("#")]),t._v(" 总问题")]),t._v(" "),_("ol",[_("li",[t._v("由于本电脑需要24小时打开成为服务器（但实际不可能一直打开）所以后续还需购买 【服务器】，所以在线上的服务器 如何配置，又成为一大问题！")])])])}),[],!1,null,null,null);v.default=r.exports}}]);